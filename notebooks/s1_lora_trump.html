<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Finetuning of Llama-3.2-3B model with LoRA on Trump tweets dataset</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../favicon.svg" rel="icon" type="image/svg+xml">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-2fdaedebe7487f361277824e4ede758e.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/copy-tex.min.js" integrity="sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A" crossorigin="anonymous"></script>


<meta property="og:title" content="Finetuning of Llama-3.2-3B model with LoRA on Trump tweets dataset">
<meta property="og:description" content="">
<meta name="twitter:title" content="Finetuning of Llama-3.2-3B model with LoRA on Trump tweets dataset">
<meta name="twitter:description" content="">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../logo.svg" alt="hse25.fmin.xyz" class="navbar-logo">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../program.html"> 
<span class="menu-text">🚀 Материалы</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../homework.html"> 
<span class="menu-text">💀 Домашка</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools tools-wide">
    <a href="https://github.com/MerkulovDaniil/hse25" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
    <a href="https://www.youtube.com/@fmin" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-youtube"></i></a>
    <a href="https://t.me/hse25_fmin" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-telegram"></i></a>
    <a href="https://fmin.xyz" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-gem"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>

<header id="title-block-header">
</header>


<div id="cell-2" class="cell" data-outputid="3fb0fab6-c054-490f-935a-adb90f0dad50" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>q transformers datasets peft accelerate bitsandbytes</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="train" class="level2">
<h2 class="anchored" data-anchor-id="train">Train</h2>
<div id="cell-4" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> peft <span class="im">import</span> LoraConfig, get_peft_model, PeftModelForCausalLM</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> BitsAndBytesConfig</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> copy <span class="im">import</span> deepcopy</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>torch.random.manual_seed(<span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>&lt;torch._C.Generator at 0x7fe5ae6cc250&gt;</code></pre>
</div>
</div>
<div id="cell-5" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the Trump Tweets dataset</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> load_dataset(<span class="st">"yunfan-y/trump-tweets-cleaned"</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the tokenizer and the base model</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">"unsloth/Llama-3.2-3B"</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForCausalLM.from_pretrained(</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    model_name,</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    device_map<span class="op">=</span><span class="st">"auto"</span>,</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    quantization_config<span class="op">=</span>BitsAndBytesConfig(load_in_8bit<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-6" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a function for generating text</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_example(prompt, model, tokenizer, max_length<span class="op">=</span><span class="dv">50</span>):</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()  <span class="co"># Убедитесь, что модель в режиме генерации</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> tokenizer(prompt, return_tensors<span class="op">=</span><span class="st">"pt"</span>, padding<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    input_ids <span class="op">=</span> inputs.input_ids.to(model.device)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    attention_mask <span class="op">=</span> inputs.attention_mask.to(model.device)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> model.generate(</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        input_ids<span class="op">=</span>input_ids,</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>        attention_mask<span class="op">=</span>attention_mask,</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>        max_length<span class="op">=</span>max_length,</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>        num_return_sequences<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>        do_sample<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>        temperature<span class="op">=</span><span class="fl">0.8</span>,</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>        top_p<span class="op">=</span><span class="fl">0.95</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tokenizer.decode(output[<span class="dv">0</span>], skip_special_tokens<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> clean_tweet(tweet):</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Remove URLs</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    tweet <span class="op">=</span> re.sub(<span class="vs">r'http\S+|www\S+|https\S+'</span>, <span class="st">''</span>, tweet, flags<span class="op">=</span>re.MULTILINE)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Remove retweets</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    tweet <span class="op">=</span> re.sub(<span class="vs">r'^RT\s+'</span>, <span class="st">''</span>, tweet)</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Remove user @ references and '#' from hashtags</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>    tweet <span class="op">=</span> re.sub(<span class="vs">r'\@\w+|\#'</span>, <span class="st">''</span>, tweet)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Remove special characters and numbers</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># tweet = re.sub(r'[^A-Za-z\d\s]', '', tweet)</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert to lowercase</span></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tweet.strip()</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Preprocessing the data</span></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> preprocess_function(examples):</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>    tweets <span class="op">=</span> examples[<span class="st">"text"</span>]  <span class="co"># Use "text" instead of "content"</span></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> [<span class="ss">f"You are Donald Trump writing a tweet about politics. Your tweet: </span><span class="sc">{</span>clean_tweet(tweet)<span class="sc">}</span><span class="ss">"</span> <span class="cf">for</span> tweet <span class="kw">in</span> tweets]</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>    model_inputs <span class="op">=</span> tokenizer(inputs, max_length<span class="op">=</span><span class="dv">512</span>, truncation<span class="op">=</span><span class="va">True</span>, padding<span class="op">=</span><span class="st">"max_length"</span>)</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>    model_inputs[<span class="st">"labels"</span>] <span class="op">=</span> model_inputs[<span class="st">"input_ids"</span>].copy()</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model_inputs</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>tokenizer.pad_token <span class="op">=</span> tokenizer.eos_token</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>tokenized_datasets <span class="op">=</span> dataset.<span class="bu">map</span>(preprocess_function, batched<span class="op">=</span><span class="va">True</span>, remove_columns<span class="op">=</span>[<span class="st">"text"</span>])</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the dataset into training and validation sets</span></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>train_test_split <span class="op">=</span> tokenized_datasets[<span class="st">"train"</span>].train_test_split(test_size<span class="op">=</span><span class="fl">0.01</span>, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> train_test_split[<span class="st">"train"</span>]</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>eval_dataset <span class="op">=</span> train_test_split[<span class="st">"test"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-7" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate text before training</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"=== Text Generation Before Training ==="</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">"Immigrants"</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(generate_example(prompt, model, tokenizer))</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare LoRA configuration</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>lora_config <span class="op">=</span> LoraConfig(</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    r<span class="op">=</span><span class="dv">64</span>,  <span class="co"># Rank of the LoRA update matrices</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    lora_alpha<span class="op">=</span><span class="dv">32</span>,  <span class="co"># LoRA scaling factor</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    target_modules<span class="op">=</span>[<span class="st">"q_proj"</span>, <span class="st">"v_proj"</span>],  <span class="co"># Modules to apply LoRA</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    lora_dropout<span class="op">=</span><span class="fl">0.1</span>,  <span class="co"># Dropout rate for LoRA</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    bias<span class="op">=</span><span class="st">"none"</span>,  <span class="co"># Do not train biases</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    task_type<span class="op">=</span><span class="st">"CAUSAL_LM"</span>  <span class="co"># Task type for causal language modeling</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Wrap the model with PEFT</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>peft_model <span class="op">=</span> get_peft_model(model, lora_config)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>output_dir <span class="op">=</span> <span class="st">"./trump_lora"</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Define training arguments</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>training_args <span class="op">=</span> TrainingArguments(</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>    output_dir<span class="op">=</span>output_dir,  <span class="co"># Directory for saving the model</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>    eval_strategy<span class="op">=</span><span class="st">"steps"</span>,  <span class="co"># No evaluation dataset</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>    logging_steps<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>    save_strategy<span class="op">=</span><span class="st">"steps"</span>,</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>    save_steps<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">3e-4</span>,</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>    per_device_eval_batch_size<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>    num_train_epochs<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>    max_steps<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>    weight_decay<span class="op">=</span><span class="fl">0.01</span>,</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>    gradient_accumulation_steps<span class="op">=</span><span class="dv">16</span>,</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>    warmup_steps<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>    logging_dir<span class="op">=</span><span class="st">"./logs"</span>,</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>    fp16<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>    report_to<span class="op">=</span><span class="st">'none'</span>,</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the Trainer with eval_dataset</span></span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> Trainer(</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>peft_model,</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>training_args,</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>    train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>    eval_dataset<span class="op">=</span>eval_dataset,</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a>trainer.train()</span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the fine-tuned model</span></span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a>peft_model.save_pretrained(output_dir)</span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a>tokenizer.save_pretrained(output_dir)</span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate text after training</span></span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"=== Text Generation After Training ==="</span>)</span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(generate_example(prompt, peft_model, tokenizer))</span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Model fine-tuned and saved!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=== Text Generation Before Training ===
Immigrants and the American Dream: The Political and Economic Legacy of Early New York
Immigrants and the American Dream: The Political and Economic Legacy of Early New York by Anthony F. C. Wallace
English | February 3, 199</code></pre>
</div>
<div class="cell-output cell-output-display">

    <div>
      
      <progress value="100" max="100" style="width:300px; height:20px; vertical-align: middle;"></progress>
      [100/100 14:01, Epoch 0/1]
    </div>
    
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Step</th>
<th data-quarto-table-cell-role="th">Training Loss</th>
<th data-quarto-table-cell-role="th">Validation Loss</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>10</td>
<td>100.107800</td>
<td>4.980176</td>
</tr>
<tr class="even">
<td>20</td>
<td>32.612900</td>
<td>0.334947</td>
</tr>
<tr class="odd">
<td>30</td>
<td>5.274200</td>
<td>0.308010</td>
</tr>
<tr class="even">
<td>40</td>
<td>4.525100</td>
<td>0.257844</td>
</tr>
<tr class="odd">
<td>50</td>
<td>3.852100</td>
<td>0.193377</td>
</tr>
<tr class="even">
<td>60</td>
<td>2.864500</td>
<td>0.175147</td>
</tr>
<tr class="odd">
<td>70</td>
<td>2.653900</td>
<td>0.171719</td>
</tr>
<tr class="even">
<td>80</td>
<td>2.623700</td>
<td>0.169075</td>
</tr>
<tr class="odd">
<td>90</td>
<td>2.646900</td>
<td>0.167437</td>
</tr>
<tr class="even">
<td>100</td>
<td>2.612200</td>
<td>0.165744</td>
</tr>
</tbody>
</table>
<p>
</p></div>
<div class="cell-output cell-output-stderr">
<pre><code>Repo card metadata block was not found. Setting CardData to empty.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=== Text Generation After Training ===
Immigrants’ rights advocates are worried that changes to immigration policies are making it harder for people to seek asylum in the United States. And those changes have also made it harder to prove that someone is eligible for asylum, according to the experts interviewed by
Model fine-tuned and saved!</code></pre>
</div>
</div>
</section>
<section id="inference" class="level2">
<h2 class="anchored" data-anchor-id="inference">Inference</h2>
<p>Seems like when we load fine-tuned model, it overwrites original model, so restart notebook just in case before inference</p>
<div id="cell-10" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"CUDA_DEVICE_ORDER"</span>]<span class="op">=</span><span class="st">'PCI_BUS_ID'</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"XLA_PYTHON_CLIENT_PREALLOCATE"</span>] <span class="op">=</span> <span class="st">'false'</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>i <span class="op">=</span> <span class="dv">6</span> <span class="co"># device number to use</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"CUDA_VISIBLE_DEVICES"</span>] <span class="op">=</span> <span class="ss">f'</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-11" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> peft <span class="im">import</span> LoraConfig, get_peft_model, PeftModelForCausalLM</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> BitsAndBytesConfig</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> copy <span class="im">import</span> deepcopy</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>torch.random.manual_seed(<span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>&lt;torch._C.Generator at 0x7f4c68630310&gt;</code></pre>
</div>
</div>
<div id="cell-12" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the Trump Tweets dataset</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> load_dataset(<span class="st">"yunfan-y/trump-tweets-cleaned"</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the tokenizer and the base model</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">"unsloth/Llama-3.2-3B"</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForCausalLM.from_pretrained(</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    model_name,</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    device_map<span class="op">=</span><span class="st">"auto"</span>,</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    quantization_config<span class="op">=</span>BitsAndBytesConfig(load_in_8bit<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-13" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a function for generating text</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_example(prompt, model, tokenizer, max_length<span class="op">=</span><span class="dv">50</span>):</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()  <span class="co"># Убедитесь, что модель в режиме генерации</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> tokenizer(prompt, return_tensors<span class="op">=</span><span class="st">"pt"</span>, padding<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    input_ids <span class="op">=</span> inputs.input_ids.to(model.device)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    attention_mask <span class="op">=</span> inputs.attention_mask.to(model.device)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> model.generate(</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>        input_ids<span class="op">=</span>input_ids,</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>        attention_mask<span class="op">=</span>attention_mask,</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>        max_length<span class="op">=</span>max_length,</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>        num_return_sequences<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>        do_sample<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>        temperature<span class="op">=</span><span class="fl">0.8</span>,</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>        top_p<span class="op">=</span><span class="fl">0.95</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tokenizer.decode(output[<span class="dv">0</span>], skip_special_tokens<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> clean_tweet(tweet):</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Remove URLs</span></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>    tweet <span class="op">=</span> re.sub(<span class="vs">r'http\S+|www\S+|https\S+'</span>, <span class="st">''</span>, tweet, flags<span class="op">=</span>re.MULTILINE)</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Remove retweets</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>    tweet <span class="op">=</span> re.sub(<span class="vs">r'^RT\s+'</span>, <span class="st">''</span>, tweet)</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Remove user @ references and '#' from hashtags</span></span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>    tweet <span class="op">=</span> re.sub(<span class="vs">r'\@\w+|\#'</span>, <span class="st">''</span>, tweet)</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Remove special characters and numbers</span></span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># tweet = re.sub(r'[^A-Za-z\d\s]', '', tweet)</span></span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert to lowercase</span></span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tweet.strip()</span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Preprocessing the data</span></span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> preprocess_function(examples):</span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a>    tweets <span class="op">=</span> examples[<span class="st">"text"</span>]  <span class="co"># Use "text" instead of "content"</span></span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> [<span class="ss">f"You are Donald Trump writing a tweet about politics. Your tweet: </span><span class="sc">{</span>clean_tweet(tweet)<span class="sc">}</span><span class="ss">"</span> <span class="cf">for</span> tweet <span class="kw">in</span> tweets]</span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a>    model_inputs <span class="op">=</span> tokenizer(inputs, max_length<span class="op">=</span><span class="dv">512</span>, truncation<span class="op">=</span><span class="va">True</span>, padding<span class="op">=</span><span class="st">"max_length"</span>)</span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a>    model_inputs[<span class="st">"labels"</span>] <span class="op">=</span> model_inputs[<span class="st">"input_ids"</span>].copy()</span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model_inputs</span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a>tokenizer.pad_token <span class="op">=</span> tokenizer.eos_token</span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a>tokenized_datasets <span class="op">=</span> dataset.<span class="bu">map</span>(preprocess_function, batched<span class="op">=</span><span class="va">True</span>, remove_columns<span class="op">=</span>[<span class="st">"text"</span>])</span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-41"><a href="#cb15-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the dataset into training and validation sets</span></span>
<span id="cb15-42"><a href="#cb15-42" aria-hidden="true" tabindex="-1"></a>train_test_split <span class="op">=</span> tokenized_datasets[<span class="st">"train"</span>].train_test_split(test_size<span class="op">=</span><span class="fl">0.01</span>, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb15-43"><a href="#cb15-43" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> train_test_split[<span class="st">"train"</span>]</span>
<span id="cb15-44"><a href="#cb15-44" aria-hidden="true" tabindex="-1"></a>eval_dataset <span class="op">=</span> train_test_split[<span class="st">"test"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="original-model" class="level3">
<h3 class="anchored" data-anchor-id="original-model">Original model</h3>
<div id="cell-15" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>train_test_split <span class="op">=</span> tokenized_datasets[<span class="st">"train"</span>].train_test_split(test_size<span class="op">=</span><span class="fl">0.01</span>, seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> train_test_split[<span class="st">"train"</span>]</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>eval_dataset <span class="op">=</span> train_test_split[<span class="st">"test"</span>]</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate both models on the evaluation dataset</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"=== Comparing Model Performance on Evaluation Dataset ==="</span>)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate original model</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>eval_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>eval_steps <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>eval_data_loader <span class="op">=</span> DataLoader(eval_dataset, batch_size<span class="op">=</span><span class="dv">4</span>, collate_fn<span class="op">=</span><span class="kw">lambda</span> x: {k: torch.tensor([d[k] <span class="cf">for</span> d <span class="kw">in</span> x]).to(model.device) <span class="cf">for</span> k <span class="kw">in</span> x[<span class="dv">0</span>].keys()})</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch <span class="kw">in</span> eval_data_loader:</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(<span class="op">**</span>{k: v <span class="cf">for</span> k, v <span class="kw">in</span> batch.items() <span class="cf">if</span> k <span class="op">!=</span> <span class="st">'labels'</span>}, labels<span class="op">=</span>batch[<span class="st">'labels'</span>])</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>        eval_loss <span class="op">+=</span> outputs.loss.item()</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>        eval_steps <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>original_perplexity <span class="op">=</span> math.exp(eval_loss <span class="op">/</span> eval_steps)</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Original Model Perplexity: </span><span class="sc">{</span>original_perplexity<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Original Model Loss: </span><span class="sc">{</span>eval_loss<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>=== Comparing Model Performance on Evaluation Dataset ===
Original Model Perplexity: 732.55
Original Model Loss: 554.11</code></pre>
</div>
</div>
<div id="cell-16" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>test_prompts <span class="op">=</span> [</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"I think, Donald Trump"</span>,</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"I think, Barack Obama"</span>,</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"I think, Joe Biden"</span>,</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"I think, the Democrats are"</span>,</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"We need to"</span>,</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-17" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> prompt <span class="kw">in</span> test_prompts:</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(generate_example(prompt, model, tokenizer))</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I think, Donald Trump will be the next President of the United States. There is a chance that he won’t but if he doesn’t then I’ll be very disappointed. To me, it’s the only way that America can survive.
America
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I think, Donald Trump, the newly elected 45th President of the United States has just pulled a fast one on us. I think, he is going to be a great President. I’m not going to hold my breath, however,
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I think, Donald Trump is the most intelligent President the US ever had, and the current one, Barack Obama is the most stupid one. I know it is hard to believe, but it is a fact. Trump is the most intelligent, because
---
</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I think, Barack Obama would be the first African American president, who will make history in the USA, but he is not the first Black president. That is actually George Washington Carver, the inventor and scientist who was the first African American president
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I think, Barack Obama will win the US election. He has a great chance, since the opposition, John McCain, has made a big mistake. He has promised to give the same tax reductions to people with a high income as to those with
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I think, Barack Obama is a really nice man. I mean, his wife is really nice too. I mean, I can't think of a better word to describe them. And I like his daughter Malia. She seems really sweet.

---
</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I think, Joe Biden, the vice president, is the strongest candidate that we’ve had in 25 years.
If you want to do more than just talk about how terrible you think Donald Trump is, you have to offer a specific vision of
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I think, Joe Biden is the first president in recent history who has the potential to be reelected to the presidency. The reason is he is a person with a sense of humor, he is a good orator, and he has a
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I think, Joe Biden’s political career has been at the brink of collapse since he was elected Vice President. It seems to me that his political career is going to be over sooner than later. The political environment is changing. His party is losing
---
</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I think, the Democrats are in trouble this time. They are the ones who have been saying that the Republicans can not be trusted. I think that they have the right to be scared. They are getting very, very, very, very,
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I think, the Democrats are now afraid of losing their super-majority in the House and Senate. And they are now trying to get the votes by offering amnesty to illegal immigrants.
The Democrats are now trying to pass amnesty, but the Republicans are
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I think, the Democrats are going to try and impeach Trump for the things they said they’d do. But it didn’t work in 1998 and it won’t work now. They tried to impeach Bush for lying about Iraq,
---
</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>We need to start doing things differently. We must begin to take care of our planet if we want to pass it on to our children. The way we travel is contributing to global warming and pollution. We need to look at ways to make our
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>We need to think hard about the impact of our choices in life.
The life of a 6 year old girl was saved by her mother’s choice to make a different kind of dinner.
We need to think hard about the impact of our choices
---
We need to look at the whole picture and get our minds around it. We need to understand what we are up against. We need to be able to see the big picture and be able to make sense of it.
---
</code></pre>
</div>
</div>
<div id="cell-18" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>test_prompts <span class="op">=</span> [</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"The United States"</span>,</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-19" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> prompt <span class="kw">in</span> test_prompts:</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(generate_example(prompt, model, tokenizer))</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>The United States has been working with its partners in the United Nations Security Council to impose sanctions on the Syrian government for its alleged use of chemical weapons in April against civilians in the town of Khan Sheikhoun in Idlib governorate. The US,
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>The United States government is a massive employer, and is always looking for qualified candidates to fill a wide variety of open employment positions in locations across the country. Below you’ll find a Qualification Summary for an active, open job listing from the Department
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>The United States of America is a federal country made up of fifty states and one federal district. It is the world’s largest industrial, military and economic power, and is the leading global superpower.
The United States of America is the third largest
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>The United States Postal Service is a government-owned corporation that has been operating under the radar for a long time. It is the sole mail delivery company in the United States and is one of the biggest companies in the world, with more than 1
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>The United States is the only country in the world that does not have a national health insurance system. In 2019, 28.5 million people had no health insurance coverage, and in 2021, 37 million people remained uninsured
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>The United States is currently ranked No. 28 on the list of the world’s countries by life expectancy at birth. It is estimated that the US will have a population of 325 million in 2015. Currently, there are nearly 
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>The United States is home to an estimated 1.2 million refugees, about half of whom arrived after 9/11. For decades, America has welcomed refugees, granting permanent residence to those fleeing persecution and war. But, in recent years
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>The United States is a nation with a long history of slavery and the legacy of slavery still affects many people today. One such legacy is the practice of slavery in the United States. This practice has been around for centuries and has had a significant impact
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>The United States has been home to a number of notable African Americans, including athletes, politicians, entertainers, and military figures. One of the most famous was Jackie Robinson, who broke the MLB color barrier in 1947. Here are 
---
The United States and the rest of the world are facing an unprecedented crisis of misinformation. As the COVID-19 pandemic and other crises have unfolded, millions of people have been bombarded with lies and fake news on social media and other platforms. Mis
---
</code></pre>
</div>
</div>
<div id="cell-20" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>test_prompts <span class="op">=</span> [</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Hillary Clinton is a"</span>,</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-21" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> prompt <span class="kw">in</span> test_prompts:</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(generate_example(prompt, model, tokenizer))</span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Hillary Clinton is a master of the backroom deal. She's not afraid to reach across the aisle to forge a deal that can get something done. Even though it might not be her ideal, she's willing to compromise to get something done.
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Hillary Clinton is a hypocrite for calling for tougher laws to stop sexual harassment in the workplace — and she should know better.
Last week, the former first lady and secretary of state blasted a federal judge who released the record of a settlement between President
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Hillary Clinton is a former U.S. Secretary of State, a former U.S. Senator from New York, and the 67th U.S. Secretary of State. She served as the First Lady of the United States from 1993 to
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Hillary Clinton is a former United States Senator from New York, and the First Lady of the United States. She is a former U.S. Secretary of State and a presidential candidate in the 2008 Democratic primaries. She is running for the Democratic
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Hillary Clinton is a racist. The former secretary of state and presidential hopeful has a long record of promoting racially charged stereotypes that were designed to undermine the civil rights movement.
But a recent poll shows that she’s also a racist among her own party.
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Hillary Clinton is a liar. She lies like a rug. The evidence is clear and strong. She lies and then she lies some more. That’s why she’s not fit to be president, but that’s not her only problem. She’s
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Hillary Clinton is a terrible liar. It’s not that she’s a terrible person, it’s that she’s a terrible politician. She should have known better than to even try to lie her way out of this one. She’s so good at
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Hillary Clinton is a "warmonger" and should not be president, Donald Trump said on Monday, setting up a likely confrontation with the former secretary of state as the presidential election looms.
In a speech at the New York Hilton hotel on
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Hillary Clinton is a dangerous woman
by Mark Steyn / September 11, 2015 / Leave a comment
Hillary Clinton and her husband Bill Clinton at the 2015 Clinton Global Initiative © Alain Jocard/AFP/Getty Images
The
---
Hillary Clinton is a former U.S. Secretary of State and former First Lady of the United States. A graduate of Yale University and Yale Law School, she served as U.S. Senator for New York from 2001 to 2009,
---
</code></pre>
</div>
</div>
</section>
<section id="lora-model" class="level3">
<h3 class="anchored" data-anchor-id="lora-model">Lora model</h3>
<p>Most of the prompts give rather the same results. Probably, I could not find any good prompts for this model. But qualitative results (loss/perplexity on evaluation dataset) speak for itself.</p>
<div id="cell-24" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate LORA model</span></span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>output_dir <span class="op">=</span> <span class="st">"./trump_lora"</span></span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>peft_model <span class="op">=</span> PeftModelForCausalLM.from_pretrained(model, output_dir)</span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>peft_eval_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a>peft_eval_steps <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb88-6"><a href="#cb88-6" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb88-7"><a href="#cb88-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch <span class="kw">in</span> eval_data_loader:</span>
<span id="cb88-8"><a href="#cb88-8" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> peft_model(<span class="op">**</span>{k: v <span class="cf">for</span> k, v <span class="kw">in</span> batch.items() <span class="cf">if</span> k <span class="op">!=</span> <span class="st">'labels'</span>}, labels<span class="op">=</span>batch[<span class="st">'labels'</span>])</span>
<span id="cb88-9"><a href="#cb88-9" aria-hidden="true" tabindex="-1"></a>        peft_eval_loss <span class="op">+=</span> outputs.loss.item()</span>
<span id="cb88-10"><a href="#cb88-10" aria-hidden="true" tabindex="-1"></a>        peft_eval_steps <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb88-11"><a href="#cb88-11" aria-hidden="true" tabindex="-1"></a>peft_perplexity <span class="op">=</span> math.exp(peft_eval_loss <span class="op">/</span> peft_eval_steps)</span>
<span id="cb88-12"><a href="#cb88-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"LORA Model Perplexity: </span><span class="sc">{</span>peft_perplexity<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb88-13"><a href="#cb88-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"LORA Model Loss: </span><span class="sc">{</span>peft_eval_loss<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb88-14"><a href="#cb88-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Perplexity Improvement: </span><span class="sc">{</span>original_perplexity <span class="op">-</span> peft_perplexity<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb88-15"><a href="#cb88-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss improvement: </span><span class="sc">{</span>eval_loss <span class="op">-</span> peft_eval_loss<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>LORA Model Perplexity: 1.18
LORA Model Loss: 13.93
Perplexity Improvement: 731.37
Loss improvement: 540.18</code></pre>
</div>
</div>
<div id="cell-25" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>test_prompts <span class="op">=</span> [</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"I think, Donald Trump"</span>,</span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"I think, Barack Obama"</span>,</span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"I think, Joe Biden"</span>,</span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"I think, the Democrats are"</span>,</span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"We need to"</span>,</span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-26" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> prompt <span class="kw">in</span> test_prompts:</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(generate_example(prompt, peft_model, tokenizer))</span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I think, Donald Trump, for all his faults, is the most interesting presidential candidate since perhaps William Jennings Bryan. The thing is, I can’t be sure what Trump is thinking. He’s an enigma.
Now, I don’t want
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I think, Donald Trump, a lot, about politics, and about the country, and about the world, and about everything else. He is a great thinker, and he thinks about everything. The reason he is successful is because he is a
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I think, Donald Trump just won the Presidential election! He will be a great President for our Country! I’m proud to call myself a Donald Trump fan! He’s smart, a great businessman, a great TV personality and a great President!
---
</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I think, Barack Obama, has set a dangerous precedent with his latest tweet regarding politics and the press. Let me explain.
There are a lot of writers out there who just write about politics, and they don’t understand politics at all. They
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I think, Barack Obama is a great man, I don't care what his politics are. He's a great man and we need a lot more men like him.
I'm the best friend you'll ever have. I'm the worst enemy
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I think, Barack Obama is a good man. I hope he is reelected as president of the United States. He has done a great job as president of the United States. I hope he will be reelected as president of the
---
</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I think, Joe Biden is a great person and a great politician. He has always been a great president and I think that he has always done a great job of leading the United States and I think that he is a great leader and I think
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I think, Joe Biden is one of the best presidents the United States of America has ever had. He is the man who brought down the Berlin Wall and the Iron Curtain. He helped end the Cold War and the threat of nuclear war.
He
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I think, Joe Biden is the best for America. He is a very intelligent and kind person, who really cares about others. He knows what is going on in America and what the best for America is. He has a lot of experience in
---
</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I think, the Democrats are being too clever by half. They are playing a game of “chicken” with the Republicans. The Republicans have not played the game of “chicken” very well. The Democrats have not played the game of
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I think, the Democrats are scared of Trump because he is a very strong leader, unlike Obama. He has a lot of political skills and I hope he wins the next election.
I think, the Democrats are scared of Trump because he is a
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>I think, the Democrats are a better party than the Republicans. I would say the Republicans are a joke. And the only thing they really have going is their big money. I think they have the most corrupt politicians in the world. I just
---
</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>We need to protect our environment and the lives of all creatures on this planet. We must protect our planet, our natural resources, our environment, and the animals that inhabit it. We must all take action to save the Earth.
We all have
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>We need to have a plan on how to deal with a crisis and the best place to start is with a crisis plan. It is important to know what type of crisis you might be facing and to have a plan in place that can be used
---
We need to protect the environment from pollution by plastic. But what about the plastic inside of us? What is your body made of? Your body is made of different parts and they all serve a different purpose. We need these parts to stay alive
---
</code></pre>
</div>
</div>
<div id="cell-27" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a>test_prompts <span class="op">=</span> [</span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"The United States"</span>,</span>
<span id="cb120-3"><a href="#cb120-3" aria-hidden="true" tabindex="-1"></a>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-28" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> prompt <span class="kw">in</span> test_prompts:</span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb121-3"><a href="#cb121-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(generate_example(prompt, peft_model, tokenizer))</span>
<span id="cb121-4"><a href="#cb121-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb121-5"><a href="#cb121-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>The United States Supreme Court has ruled that federal law does not grant standing to individuals who simply make claims that they were damaged by another party’s actions. In Spokeo, Inc. v. Robins, the Court explained that “standing is
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>The United States’ trade deficit with China was $34.9 billion in the third quarter of 2017, the Commerce Department reported on Tuesday. The trade deficit with China was $375.2 billion in 2017, up from $
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>The United States Air Force announced today that the B-52H Stratofortress has earned a top spot on the prestigious 2017 Time Magazine’s Top 100 of the World’s Greatest Machines list. The venerable long-range bomber took
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>The United States Department of State has announced that it is accepting applications for the Diversity Visa Lottery program for the year 2020. The DV-2020 lottery will offer 55,000 visas for immigrants to the USA who would like to live
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>The United States is set to host its first ever esports World Cup in Dallas, Texas at the Dallas Convention Center from August 2nd to 4th. The event will be held in the same venue as the International eSports Federation (iSF
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>The United States is a nation of immigrants, with people from around the world coming to America in search of a better life. However, the process of immigrating to the United States can be complex and daunting, especially for those who are not familiar
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>The United States has become a global superpower as the result of the country's abundant natural resources, efficient markets, and large and motivated population. The United States has a great deal of natural resources, including forests, minerals, oil, and gas
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>The United States is a country of immigrants, and immigrants have always been an important part of our culture. This is why we are such a diverse and multicultural nation, with people from all over the world coming to make their lives here. If you
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>The United States of America is a federal republic of 50 states and the District of Columbia (DC). The 50 states are the principal political divisions of the country. The District of Columbia is a federal district and is not a state. There
---
The United States is home to many unique attractions, including the Statue of Liberty and the Golden Gate Bridge. The country is also well known for its delicious cuisine, which ranges from the iconic burgers and pizza to the diverse range of international dishes. From
---
</code></pre>
</div>
</div>
<div id="cell-29" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb140"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a>test_prompts <span class="op">=</span> [</span>
<span id="cb140-2"><a href="#cb140-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Hillary Clinton is a"</span>,</span>
<span id="cb140-3"><a href="#cb140-3" aria-hidden="true" tabindex="-1"></a>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-30" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb141"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> prompt <span class="kw">in</span> test_prompts:</span>
<span id="cb141-2"><a href="#cb141-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb141-3"><a href="#cb141-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(generate_example(prompt, peft_model, tokenizer))</span>
<span id="cb141-4"><a href="#cb141-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb141-5"><a href="#cb141-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Hillary Clinton is a bad role model for our children.
This should be the biggest concern for all parents with children of voting age, but especially parents who support a candidate for President.
I am not a Clinton supporter, but I do believe that the
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Hillary Clinton is a good writer. She’s a good speaker. She’s a good politician. I don’t believe she’s a good person. And if you want to be president you need to be a good person.
I don’t know if
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Hillary Clinton is a woman of many contradictions: one of the smartest in the world, and yet a political novice with little experience running for office; a brilliant negotiator, and yet a poor campaigner who has never been able to rally her
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Hillary Clinton is a liar, a hypocrite, and a crook. She has been for years. She is a disgusting person who does not deserve the office of President. She is a weakling who would not be a good leader, she
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Hillary Clinton is a real estate investor and owner of a company with a multimillion-dollar portfolio of real estate investments. Her investments include a building in New York City and in Florida. She has also invested in businesses in the United States and abroad.
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Hillary Clinton is a terrible candidate for president of the United States. She is bad on domestic issues. She is bad on foreign issues. She is bad on economics. And she is bad on the Constitution. She would be the worst president we have
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Hillary Clinton is a self-serving politician who uses her position to sell access and influence to donors and special interests, including foreign governments. She is the most corrupt and untrustworthy candidate ever to seek the presidency. She is a liar who has been
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Hillary Clinton is a true fighter and one of the most extraordinary women of all time. Her book Living History is a great read. I’m sure she will continue to do great things for America and the world.
---</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Hillary Clinton is a major liar and manipulator who would do anything to gain power.
Her policies are a disaster for America and the world. Her agenda is a threat to our freedoms and the Constitution.
She has a history of dishonesty and corruption
---
Hillary Clinton is a lying scum sucking whore who is only interested in selling her ass for a buck and lining her pockets. I don't know why she is even allowed to run for office. She is a disgrace to the country and should be
---
</code></pre>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/hse25\.fmin\.xyz");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions"><ul><li><a href="https://github.dev/MerkulovDaniil/hse25/blob/main/notebooks/s1_lora_trump.ipynb" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></div></div></footer></body></html>